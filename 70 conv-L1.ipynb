{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=26500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Xtrain_challenge_owkin.csv',nrows=N)\n",
    "data=data.drop('Ids', axis=1)\n",
    "data=data.values\n",
    "y = pd.read_csv('./challenge_output_data_training_file_disease_prediction_from_dna_data.csv',nrows=N,sep=';')\n",
    "y=y.drop('Ids', axis=1)\n",
    "y=y.values\n",
    " ## maybe concatenate the SNPs ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Should be paire 2 by 2 ? Careful to onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataAgg=data.astype('str')\n",
    "#dataAggOdd=dataAgg[:, 0::2]\n",
    "#dataAggEven=dataAgg[:, 1::2]\n",
    "#dataAgg=np.core.defchararray.add(dataAggOdd,dataAggEven)\n",
    "#dataAgg=dataAgg.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_dict = {1:1, 0:0, 11:3, 10:2}\n",
    "#dataAgg=np.vectorize(my_dict.get)(dataAgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataAggHot=(np.arange(dataAgg.max()) == dataAgg[...,None]-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataAggHot=np.reshape(np.ravel(dataAggHot), (N, 54372))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meanH=dataAggHot.mean()\n",
    "#stdH=dataAggHot.std()\n",
    "#dataAggHot=(dataAggHot-meanH)/stdH\n",
    "#x_trainH, x_testH, y_trainH, y_testH = train_test_split(dataAggHot,y.ravel(),test_size=0.2,train_size=0.8,random_state=777)\n",
    "#print(\"Size of training set = \"+str(len(x_trainH)))\n",
    "#print(\"Size of test set = \"+str(len(x_testH)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nope ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set = 21200\n",
      "Size of test set = 5300\n"
     ]
    }
   ],
   "source": [
    "mean=data.mean()\n",
    "std=data.std()\n",
    "data=(data-mean)/std\n",
    "x_train, x_test, y_train, y_test = train_test_split(data,y.ravel(),test_size=0.2,train_size=0.8,random_state=777)\n",
    "print(\"Size of training set = \"+str(len(x_train)))\n",
    "print(\"Size of test set = \"+str(len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=36248"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm_rbf = svm.SVC(kernel='rbf', C=1e3, gamma=0.1)\n",
    "#svm_lin = svm.SVC(kernel='linear', C=1e3)\n",
    "#svm_poly = svm.SVC(kernel='poly', C=1e3, degree=2)\n",
    "#y_rbf = svm_rbf.fit(x_train, y_train).predict(x_test)\n",
    "#y_lin = svm_lin.fit(x_train, y_train).predict(x_test)\n",
    "#y_poly = svm_poly.fit(x_train, y_train).predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(roc_auc_score(y_test,y_rbf))\n",
    "#print(roc_auc_score(y_test,y_lin))\n",
    "#print(roc_auc_score(y_test,y_poly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(accuracy_score(y_test,y_rbf))\n",
    "#print(accuracy_score(y_test,y_lin))\n",
    "#print(accuracy_score(y_test,y_poly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-1,1e-2,1e-3, 1,10],\n",
    "                     'C': [1e-3,1e-2,1e-1,1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1e-3,1e-2,1e-1,1, 10, 100, 900,1000,1100,1200]}]\n",
    "\n",
    "\n",
    "#clf = GridSearchCV(svm.SVC(C=1), tuned_parameters, cv=5)\n",
    "#clf.fit(x_train, y_train.ravel())\n",
    "#print(clf.best_params_)\n",
    "#y_true, y_pred = y_test, clf.predict(x_test)\n",
    "#print(accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a full grid over all parameters\n",
    "clf = RandomForestClassifier(n_estimators=200)\n",
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [2, 3, 5,10,20],\n",
    "              \"min_samples_leaf\": [1, 3, 5,10,20],\n",
    "              \"bootstrap\": [True],\n",
    "              \"criterion\": [\"gini\"]}\n",
    "#grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "#grid_search.fit(x_train, y_train.ravel())\n",
    "#print(grid_search.best_params_)\n",
    "#y_true, y_pred = y_test, grid_search.predict(x_test)\n",
    "#print(accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One H data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a full grid over all parameters\n",
    "clf = RandomForestClassifier(n_estimators=200)\n",
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [2, 3, 5,10,20],\n",
    "              \"min_samples_leaf\": [1, 3, 5,10,20],\n",
    "              \"bootstrap\": [True],\n",
    "              \"criterion\": [\"gini\"]}\n",
    "#grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "#grid_search.fit(x_trainH, y_train.ravel())\n",
    "#print(grid_search.best_params_)\n",
    "#y_true, y_pred = y_test, grid_search.predict(x_testH)\n",
    "#print(accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm_rbf = svm.SVC(kernel='rbf', C=1e3, gamma=0.1)\n",
    "#svm_lin = svm.SVC(kernel='linear', C=1e3)\n",
    "#svm_poly = svm.SVC(kernel='poly', C=1e3, degree=2)\n",
    "#y_rbf = svm_rbf.fit(x_trainH, y_train).predict(x_testH)\n",
    "#y_lin = svm_lin.fit(x_trainH, y_train).predict(x_testH)\n",
    "#y_poly = svm_poly.fit(x_trainH, y_train).predict(x_testH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(accuracy_score(y_test,y_rbf))\n",
    "#print(accuracy_score(y_test,y_lin))\n",
    "#print(accuracy_score(y_test,y_poly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-1,1e-2,1e-3, 1,10],\n",
    "#                     'C': [1e-3,1e-2,1e-1,1, 10, 100, 1000]},\n",
    "#                    {'kernel': ['linear'], 'C': [1e-3,1e-2,1e-1,1, 10, 100, 900,1000,1100,1200]}]#\n",
    "\n",
    "\n",
    "#clf = GridSearchCV(svm.SVC(C=1), tuned_parameters, cv=5)\n",
    "#clf.fit(x_trainH, y_train.ravel())\n",
    "#print(clf.best_params_)\n",
    "#y_true, y_pred = y_test, clf.predict(x_testH)\n",
    "#print(accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Flatten, Dropout, Merge\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvNet( width,  trainable=False):\n",
    "    \n",
    " \n",
    "    \n",
    "    sequence_input = Input(shape=(width,1), dtype=\"float32\", name=\"Input\")\n",
    "    \n",
    " #   l_conv0 = Conv1D(filters=64, kernel_size=5, activation='relu')(sequence_input)\n",
    "  #  l_pool0 = MaxPooling1D(pool_size=3)(l_conv0)\n",
    "    \n",
    "    convs = []\n",
    "    filter_sizes = [3, 4, 5]\n",
    "    \n",
    "    for filter_size in filter_sizes:\n",
    "        l_conv = Conv1D(filters=64, kernel_size=filter_size, activation='relu',activity_regularizer=regularizers.l1(0.0000005))(sequence_input)\n",
    "        l_pool = MaxPooling1D(pool_size=3)(l_conv)\n",
    "        convs.append(l_pool)\n",
    "    \n",
    "    l_merge = Merge(mode='concat', concat_axis=1, name=\"Merge\")(convs)\n",
    "    \n",
    "    l_conv1 = Conv1D(filters=32, kernel_size=5, activation='relu')(l_merge)\n",
    "\n",
    "    \n",
    "    l_drop  = Dropout(0.5)(l_conv1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    convs = []# ?\n",
    "    for filter_size in filter_sizes:\n",
    "        l_conv = Conv1D(filters=64, kernel_size=filter_size, activation='relu')(l_drop)\n",
    "        l_pool = MaxPooling1D(pool_size=3)(l_conv)\n",
    "        convs.append(l_pool)\n",
    "    \n",
    "    l_merge2 = Merge(mode='concat', concat_axis=1, name=\"Merge\")(convs)\n",
    "    \n",
    "    l_conv2 = Conv1D(filters=64, kernel_size=5, activation='relu')(l_merge)\n",
    "    l_pool2 = MaxPooling1D(pool_size=10)(l_conv1)\n",
    "    \n",
    "    l_drop2  = Dropout(0.5)(l_pool2)\n",
    "    \n",
    "    l_flat2  = Flatten(name=\"Flatten\")(l_drop2)\n",
    "    \n",
    "    l_dense = Dense(100, activation='relu', name=\"Dense\")(l_flat2)\n",
    "    \n",
    "    \n",
    "    preds = Dense(2, activation='softmax', name=\"Output\")(l_dense)\n",
    "    \n",
    "    model = Model(sequence_input, preds)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_t, x_val, y_train_t, y_val = train_test_split(x_train,y_train.ravel(),test_size=0.2,train_size=0.8,random_state=777)\n",
    "\n",
    "t,_=x_train_t.shape\n",
    "\n",
    "x_train_t=np.reshape(x_train_t,(t, 36248,1))\n",
    "y_train_t=np.reshape(y_train_t,(t, 1))\n",
    "\n",
    "t,_=x_val.shape\n",
    "x_val=np.reshape(x_val,(t, 36248,1))\n",
    "y_val=np.reshape(y_val,(t, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:18: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:33: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet(\n",
    "                w, \\\n",
    "                trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 36248, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 36246, 64)    256         Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 36245, 64)    320         Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 36244, 64)    384         Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 12082, 64)    0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 12081, 64)    0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 12081, 64)    0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Merge (Merge)                   (None, 36244, 64)    0           max_pooling1d_8[0][0]            \n",
      "                                                                 max_pooling1d_9[0][0]            \n",
      "                                                                 max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 36240, 32)    10272       Merge[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 3624, 32)     0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 3624, 32)     0           max_pooling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Flatten (Flatten)               (None, 115968)       0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Dense (Dense)                   (None, 100)          11596900    Flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Output (Dense)                  (None, 2)            202         Dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 11,608,334\n",
      "Trainable params: 11,608,334\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Create checkpoint that saves the weights each time validation set at each epoch is outperformed by the last one## Creat \n",
    "filepath=\"weights_bestsspenalty.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, \\\n",
    "                             monitor=\"val_acc\", \\\n",
    "                             verbose=1, \\\n",
    "                             save_best_only=True, \\\n",
    "                             mode=\"max\")\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = conv.fit(x_train_t, y_train_t, \\\n",
    "#                    validation_data=(x_val, y_val), \\\n",
    "#                    epochs=100, \\\n",
    "#                    batch_size=2, \\\n",
    "#                    callbacks=callbacks_list, \\\n",
    "#                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "y_train_t2 = to_categorical(y_train_t, num_classes=2)\n",
    "y_val2 = to_categorical(y_val, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss='binary_crossentropy', \\\n",
    "              optimizer=Adam(lr=1e-4), \\\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16960 samples, validate on 4240 samples\n",
      "Epoch 1/60\n",
      "16960/16960 [==============================] - 1172s 69ms/step - loss: 1.0945 - acc: 0.5649 - val_loss: 0.6835 - val_acc: 0.5717\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.57170, saving model to weights_bestsspenalty.hdf5\n",
      "Epoch 2/60\n",
      "16960/16960 [==============================] - 1216s 72ms/step - loss: 0.6656 - acc: 0.6043 - val_loss: 0.6290 - val_acc: 0.6672\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.57170 to 0.66722, saving model to weights_bestsspenalty.hdf5\n",
      "Epoch 3/60\n",
      "16960/16960 [==============================] - 1212s 71ms/step - loss: 0.6131 - acc: 0.6703 - val_loss: 0.6128 - val_acc: 0.6660\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.66722\n",
      "Epoch 4/60\n",
      "16960/16960 [==============================] - 1213s 71ms/step - loss: 0.5835 - acc: 0.6960 - val_loss: 0.5972 - val_acc: 0.6795\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.66722 to 0.67948, saving model to weights_bestsspenalty.hdf5\n",
      "Epoch 5/60\n",
      "16960/16960 [==============================] - 1212s 71ms/step - loss: 0.5561 - acc: 0.7172 - val_loss: 0.5907 - val_acc: 0.6833\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.67948 to 0.68325, saving model to weights_bestsspenalty.hdf5\n",
      "Epoch 6/60\n",
      " 9912/16960 [================>.............] - ETA: 7:55 - loss: 0.5245 - acc: 0.7446"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_t, y_train_t2, \\\n",
    "                    validation_data=(x_val, y_val2), \\\n",
    "                    epochs=60, \\\n",
    "                    batch_size=8, \\\n",
    "                    callbacks=callbacks_list, \\\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history_dicthistory_  = history.history\n",
    "train_loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "num_epochs = 40\n",
    "epochs = range(1, num_epochs + 1)\n",
    "\n",
    "plt.plot(epochs, train_loss_values, 'r', label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss_values, 'b', label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history_dicthistory_  = history.history\n",
    "train_acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "num_epochs = 40\n",
    "epochs = range(1, num_epochs + 1)\n",
    "\n",
    "plt.plot(epochs, train_acc_values, 'r', label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_acc_values, 'b', label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,_=x_test.shape\n",
    "x_test_t=np.reshape(x_test,(t, 36248,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(x_test_t, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_01 = (y_pred[:,0] < 0.5).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc_score(labels_01,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
