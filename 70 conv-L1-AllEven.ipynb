{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=26500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Xtrain_challenge_owkin.csv',nrows=N)\n",
    "data=data.drop('Ids', axis=1)\n",
    "data=data.values\n",
    "y = pd.read_csv('./challenge_output_data_training_file_disease_prediction_from_dna_data.csv',nrows=N,sep=';')\n",
    "y=y.drop('Ids', axis=1)\n",
    "y=y.values\n",
    " ## maybe concatenate the SNPs ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Should be paire 2 by 2 ? Careful to onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataAgg=data.astype('str')\n",
    "#dataAggOdd=dataAgg[:, 0::2]\n",
    "#dataAggEven=dataAgg[:, 1::2]\n",
    "#dataAgg=np.core.defchararray.add(dataAggOdd,dataAggEven)\n",
    "#dataAgg=dataAgg.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_dict = {1:1, 0:0, 11:3, 10:2}\n",
    "#dataAgg=np.vectorize(my_dict.get)(dataAgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataAggHot=(np.arange(dataAgg.max()) == dataAgg[...,None]-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataAggHot=np.reshape(np.ravel(dataAggHot), (N, 54372))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meanH=dataAggHot.mean()\n",
    "#stdH=dataAggHot.std()\n",
    "#dataAggHot=(dataAggHot-meanH)/stdH\n",
    "#x_trainH, x_testH, y_trainH, y_testH = train_test_split(dataAggHot,y.ravel(),test_size=0.2,train_size=0.8,random_state=777)\n",
    "#print(\"Size of training set = \"+str(len(x_trainH)))\n",
    "#print(\"Size of test set = \"+str(len(x_testH)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nope ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=data.mean()\n",
    "std=data.std()\n",
    "data=(data-mean)/std\n",
    "x_train, x_test, y_train, y_test = train_test_split(data,y.ravel(),test_size=0.2,train_size=0.8,random_state=777)\n",
    "print(\"Size of training set = \"+str(len(x_train)))\n",
    "print(\"Size of test set = \"+str(len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=36248"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm_rbf = svm.SVC(kernel='rbf', C=1e3, gamma=0.1)\n",
    "#svm_lin = svm.SVC(kernel='linear', C=1e3)\n",
    "#svm_poly = svm.SVC(kernel='poly', C=1e3, degree=2)\n",
    "#y_rbf = svm_rbf.fit(x_train, y_train).predict(x_test)\n",
    "#y_lin = svm_lin.fit(x_train, y_train).predict(x_test)\n",
    "#y_poly = svm_poly.fit(x_train, y_train).predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(roc_auc_score(y_test,y_rbf))\n",
    "#print(roc_auc_score(y_test,y_lin))\n",
    "#print(roc_auc_score(y_test,y_poly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(accuracy_score(y_test,y_rbf))\n",
    "#print(accuracy_score(y_test,y_lin))\n",
    "#print(accuracy_score(y_test,y_poly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-1,1e-2,1e-3, 1,10],\n",
    "                     'C': [1e-3,1e-2,1e-1,1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1e-3,1e-2,1e-1,1, 10, 100, 900,1000,1100,1200]}]\n",
    "\n",
    "\n",
    "#clf = GridSearchCV(svm.SVC(C=1), tuned_parameters, cv=5)\n",
    "#clf.fit(x_train, y_train.ravel())\n",
    "#print(clf.best_params_)\n",
    "#y_true, y_pred = y_test, clf.predict(x_test)\n",
    "#print(accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a full grid over all parameters\n",
    "clf = RandomForestClassifier(n_estimators=200)\n",
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [2, 3, 5,10,20],\n",
    "              \"min_samples_leaf\": [1, 3, 5,10,20],\n",
    "              \"bootstrap\": [True],\n",
    "              \"criterion\": [\"gini\"]}\n",
    "#grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "#grid_search.fit(x_train, y_train.ravel())\n",
    "#print(grid_search.best_params_)\n",
    "#y_true, y_pred = y_test, grid_search.predict(x_test)\n",
    "#print(accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One H data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a full grid over all parameters\n",
    "clf = RandomForestClassifier(n_estimators=200)\n",
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [2, 3, 5,10,20],\n",
    "              \"min_samples_leaf\": [1, 3, 5,10,20],\n",
    "              \"bootstrap\": [True],\n",
    "              \"criterion\": [\"gini\"]}\n",
    "#grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "#grid_search.fit(x_trainH, y_train.ravel())\n",
    "#print(grid_search.best_params_)\n",
    "#y_true, y_pred = y_test, grid_search.predict(x_testH)\n",
    "#print(accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm_rbf = svm.SVC(kernel='rbf', C=1e3, gamma=0.1)\n",
    "#svm_lin = svm.SVC(kernel='linear', C=1e3)\n",
    "#svm_poly = svm.SVC(kernel='poly', C=1e3, degree=2)\n",
    "#y_rbf = svm_rbf.fit(x_trainH, y_train).predict(x_testH)\n",
    "#y_lin = svm_lin.fit(x_trainH, y_train).predict(x_testH)\n",
    "#y_poly = svm_poly.fit(x_trainH, y_train).predict(x_testH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(accuracy_score(y_test,y_rbf))\n",
    "#print(accuracy_score(y_test,y_lin))\n",
    "#print(accuracy_score(y_test,y_poly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-1,1e-2,1e-3, 1,10],\n",
    "#                     'C': [1e-3,1e-2,1e-1,1, 10, 100, 1000]},\n",
    "#                    {'kernel': ['linear'], 'C': [1e-3,1e-2,1e-1,1, 10, 100, 900,1000,1100,1200]}]#\n",
    "\n",
    "\n",
    "#clf = GridSearchCV(svm.SVC(C=1), tuned_parameters, cv=5)\n",
    "#clf.fit(x_trainH, y_train.ravel())\n",
    "#print(clf.best_params_)\n",
    "#y_true, y_pred = y_test, clf.predict(x_testH)\n",
    "#print(accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Flatten, Dropout, Merge\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvNet( width,  trainable=False):\n",
    "    \n",
    " \n",
    "    \n",
    "    sequence_input = Input(shape=(width,1), dtype=\"float32\", name=\"Input\")\n",
    "    \n",
    " #   l_conv0 = Conv1D(filters=64, kernel_size=5, activation='relu')(sequence_input)\n",
    "  #  l_pool0 = MaxPooling1D(pool_size=3)(l_conv0)\n",
    "    \n",
    "    convs = []\n",
    "    filter_sizes = [2, 4, 6]\n",
    "    \n",
    "    for filter_size in filter_sizes:\n",
    "        l_conv = Conv1D(filters=64, kernel_size=filter_size, activation='relu',activity_regularizer=regularizers.l1(0.00001))(sequence_input)\n",
    "        l_pool = MaxPooling1D(pool_size=4)(l_conv)\n",
    "        convs.append(l_pool)\n",
    "    \n",
    "    l_merge = Merge(mode='concat', concat_axis=1, name=\"Merge\")(convs)\n",
    "    \n",
    "    l_conv1 = Conv1D(filters=32, kernel_size=4, activation='relu')(l_merge)\n",
    "\n",
    "    \n",
    "    l_drop  = Dropout(0.5)(l_conv1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    convs = []# ?\n",
    "    for filter_size in filter_sizes:\n",
    "        l_conv = Conv1D(filters=64, kernel_size=filter_size, activation='relu')(l_drop)\n",
    "        l_pool = MaxPooling1D(pool_size=4)(l_conv)\n",
    "        convs.append(l_pool)\n",
    "    \n",
    "    l_merge2 = Merge(mode='concat', concat_axis=1, name=\"Merge\")(convs)\n",
    "    \n",
    "    l_conv2 = Conv1D(filters=64, kernel_size=4, activation='relu')(l_merge)\n",
    "    l_pool2 = MaxPooling1D(pool_size=6)(l_conv1)\n",
    "    \n",
    "    l_drop2  = Dropout(0.5)(l_pool2)\n",
    "    \n",
    "    l_flat2  = Flatten(name=\"Flatten\")(l_drop2)\n",
    "    \n",
    "    l_dense0 = Dense(200, activation='relu', name=\"Dense\")(l_flat2)\n",
    "    \n",
    "    l_drop3  = Dropout(0.5)(l_dense0)\n",
    "    l_dense = Dense(100, activation='relu', name=\"Dense2\")(l_drop3)\n",
    "    \n",
    "        \n",
    "    preds = Dense(2, activation='softmax', name=\"Output\")(l_dense)\n",
    "    \n",
    "    model = Model(sequence_input, preds)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_t, x_val, y_train_t, y_val = train_test_split(x_train,y_train.ravel(),test_size=0.2,train_size=0.8,random_state=777)\n",
    "\n",
    "t,_=x_train_t.shape\n",
    "\n",
    "x_train_t=np.reshape(x_train_t,(t, 36248,1))\n",
    "y_train_t=np.reshape(y_train_t,(t, 1))\n",
    "\n",
    "t,_=x_val.shape\n",
    "x_val=np.reshape(x_val,(t, 36248,1))\n",
    "y_val=np.reshape(y_val,(t, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ConvNet(\n",
    "                w, \\\n",
    "                trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Create checkpoint that saves the weights each time validation set at each epoch is outperformed by the last one## Creat \n",
    "filepath=\"weights_bestsspenalty even.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, \\\n",
    "                             monitor=\"val_acc\", \\\n",
    "                             verbose=1, \\\n",
    "                             save_best_only=True, \\\n",
    "                             mode=\"max\")\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = conv.fit(x_train_t, y_train_t, \\\n",
    "#                    validation_data=(x_val, y_val), \\\n",
    "#                    epochs=100, \\\n",
    "#                    batch_size=2, \\\n",
    "#                    callbacks=callbacks_list, \\\n",
    "#                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "y_train_t2 = to_categorical(y_train_t, num_classes=2)\n",
    "y_val2 = to_categorical(y_val, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss='binary_crossentropy', \\\n",
    "              optimizer=Adam(lr=1e-5), \\\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train_t, y_train_t2, \\\n",
    "                    validation_data=(x_val, y_val2), \\\n",
    "                    epochs=30, \\\n",
    "                    batch_size=6, \\\n",
    "                    callbacks=callbacks_list, \\\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history_dicthistory_  = history.history\n",
    "train_loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "num_epochs = 30\n",
    "epochs = range(1, num_epochs + 1)\n",
    "\n",
    "plt.plot(epochs, train_loss_values, 'r', label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss_values, 'b', label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history_dicthistory_  = history.history\n",
    "train_acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "num_epochs = 30\n",
    "epochs = range(1, num_epochs + 1)\n",
    "\n",
    "plt.plot(epochs, train_acc_values, 'r', label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_acc_values, 'b', label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,_=x_test.shape\n",
    "x_test_t=np.reshape(x_test,(t, 36248,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(x_test_t, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_01 = (y_pred[:,0] < 0.5).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc_score(labels_01,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datat_tempdatat_te  = pd.read_csv('./Xtest_challenge_owkin.csv')\n",
    "datat=datat_tempdatat_te.drop('Ids', axis=1)\n",
    "datat=datat.values\n",
    "datat=(datat-mean)/std\n",
    "t,_=datat.shape\n",
    "x_test_no_answer=np.reshape(datat,(t, 36248,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(x_test_no_answer, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('predConvL1penalty',y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
